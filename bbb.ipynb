{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb1ce11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:01:31.442913Z",
     "start_time": "2021-12-28T07:01:29.169042Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # specify to ignore warning messages\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "from statsmodels.tools.sm_exceptions import HessianInversionWarning\n",
    "warnings.simplefilter('ignore', category=ConvergenceWarning)\n",
    "warnings.simplefilter('ignore', category=HessianInversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7291f5a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:04:16.571125Z",
     "start_time": "2021-12-28T07:04:10.587724Z"
    }
   },
   "outputs": [],
   "source": [
    "# 특정파일을 절대경로로 datafile read함.\n",
    "df_train = pd.read_csv('funda_train.csv')\n",
    "df_sub = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0511b2a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:04:35.923974Z",
     "start_time": "2021-12-28T07:04:19.088129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train['transaction_time'] = df_train['transacted_date'] + \"-\" + df_train['transacted_time']\n",
    "df_train['transaction_time'] = pd.to_datetime(df_train['transaction_time'], format='%Y-%m-%d-%H:%M', infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "228fd5a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:04:40.502188Z",
     "start_time": "2021-12-28T07:04:40.034972Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.drop(['transacted_date', 'transacted_time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db92d707",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87131bf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:05:21.548910Z",
     "start_time": "2021-12-28T07:05:21.532269Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5807408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:10:15.370276Z",
     "start_time": "2021-12-28T07:10:15.353921Z"
    }
   },
   "outputs": [],
   "source": [
    "def cancel_delete(df_):\n",
    "    df = df_.copy(deep=True)\n",
    "    store_id_lst = df.store_id.unique()\n",
    "    del_idx = []\n",
    "    extra_idx = []\n",
    "    for s_id in (store_id_lst):\n",
    "        tmp = df[(df['store_id'] == s_id)]\n",
    "        minus_amount = tmp[tmp['amount'] < 0]\n",
    "        for idx, col in minus_amount.iterrows():\n",
    "            df_search = tmp[(tmp['amount'] == - col['amount']) &\n",
    "                      (tmp['card_id'] == col['card_id']) &\n",
    "                      (tmp['transaction_time'] <= col['transaction_time']) &\n",
    "                      (tmp['card_company'] == col['card_company'])]\n",
    "            if len(df_search) == 0:\n",
    "        # 결제 취소했지만 데이터에 없는 경우 -> 추후 제거\n",
    "                extra_idx.append(idx)\n",
    "            else:\n",
    "        # 가장 최근 결제 내역을 제거\n",
    "                del_idx.append(df_search.index[-1])\n",
    "                del_idx.append(idx)\n",
    "\n",
    "    df.drop(del_idx, axis=0, inplace=True)\n",
    "    df.drop(extra_idx, axis=0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4085d9a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:12:54.697834Z",
     "start_time": "2021-12-28T07:11:27.064093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_cleaned = cancel_delete(df_train)\n",
    "# 총 매출이 0인 경우도 데이터에서 제거\n",
    "df_cleaned.drop(df_cleaned[df_cleaned.amount <= 0].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e23235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:16:15.720265Z",
     "start_time": "2021-12-28T07:16:15.552924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>card_id</th>\n",
       "      <th>card_company</th>\n",
       "      <th>installment_term</th>\n",
       "      <th>region</th>\n",
       "      <th>type_of_business</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-01 13:13:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기타 미용업</td>\n",
       "      <td>1857.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 18:12:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기타 미용업</td>\n",
       "      <td>857.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 18:52:00</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기타 미용업</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 20:22:00</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기타 미용업</td>\n",
       "      <td>7857.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-02 11:06:00</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기타 미용업</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     store_id  card_id card_company  installment_term region  \\\n",
       "transaction_time                                                               \n",
       "2016-06-01 13:13:00         0        0            b                 0    NaN   \n",
       "2016-06-01 18:12:00         0        1            h                 0    NaN   \n",
       "2016-06-01 18:52:00         0        2            c                 0    NaN   \n",
       "2016-06-01 20:22:00         0        3            a                 0    NaN   \n",
       "2016-06-02 11:06:00         0        4            c                 0    NaN   \n",
       "\n",
       "                    type_of_business       amount  \n",
       "transaction_time                                   \n",
       "2016-06-01 13:13:00           기타 미용업  1857.142857  \n",
       "2016-06-01 18:12:00           기타 미용업   857.142857  \n",
       "2016-06-01 18:52:00           기타 미용업  2000.000000  \n",
       "2016-06-01 20:22:00           기타 미용업  7857.142857  \n",
       "2016-06-02 11:06:00           기타 미용업  2000.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep = df_cleaned.set_index('transaction_time')\n",
    "df_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4c8043e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:21:21.328845Z",
     "start_time": "2021-12-28T07:21:21.307513Z"
    }
   },
   "outputs": [],
   "source": [
    "# 최근 데이터가 없는 상점을 찾음.\n",
    "def no_data(df, at_least_need_date = '2019-01-01'):\n",
    "    u_store_id = df['store_id'].unique()\n",
    "    del_store_id_lst = []\n",
    "    for s_id in u_store_id:\n",
    "        df_tmp = df[df['store_id'] == s_id]\n",
    "    # 최근 매출 날짜를 봄\n",
    "        df_tmp = df_tmp.resample('M').sum().index[-1]\n",
    "    # 2019년 1월 1일 이전이면 예측 0으로. 이 부분은 나중에 바꿔도 됨.\n",
    "        if df_tmp < datetime.strptime(at_least_need_date, \"%Y-%m-%d\"):\n",
    "            del_store_id_lst.append(s_id)\n",
    "    return del_store_id_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f96dd4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:21:40.795378Z",
     "start_time": "2021-12-28T07:21:23.627784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[111,\n",
       " 257,\n",
       " 374,\n",
       " 479,\n",
       " 619,\n",
       " 632,\n",
       " 640,\n",
       " 772,\n",
       " 795,\n",
       " 802,\n",
       " 838,\n",
       " 999,\n",
       " 1217,\n",
       " 1233,\n",
       " 1520,\n",
       " 1527,\n",
       " 1567,\n",
       " 1598,\n",
       " 1604,\n",
       " 1685,\n",
       " 1967,\n",
       " 2027,\n",
       " 2053,\n",
       " 2058,\n",
       " 2086,\n",
       " 2119]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "no_data_store_id = no_data(df_prep)\n",
    "no_data_store_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27a410a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:22:17.732032Z",
     "start_time": "2021-12-28T07:22:17.714506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111, 257, 374, 479, 619, 632, 640, 772, 795, 802, 838, 999, 1217, 1233, 1520, 1527, 1567, 1598, 1604, 1685, 1967, 2027, 2053, 2058, 2086, 2119]\n"
     ]
    }
   ],
   "source": [
    "# 전부 2018년도까지만 매출 데이터 있음, 2019년도 매출 데이터가 없음 \n",
    "print(no_data_store_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e784434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:22:38.351034Z",
     "start_time": "2021-12-28T07:22:37.781018Z"
    }
   },
   "outputs": [],
   "source": [
    "df_prep.fillna(\"NULL\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a65e8850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:23:03.046652Z",
     "start_time": "2021-12-28T07:22:59.564950Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from statsmodels.tsa.arima_model import ARIMA, ARMAResults\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4839a08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T07:23:32.247078Z",
     "start_time": "2021-12-28T07:23:32.235952Z"
    }
   },
   "outputs": [],
   "source": [
    "# stationary test\n",
    "def adfTest(timeseries, diff):\n",
    "    if diff == 0:\n",
    "        result = adfuller(timeseries)\n",
    "    else:\n",
    "        diff_ts = timeseries.copy(deep=True)\n",
    "        for d in range(1, diff+1):\n",
    "            diff_ts = (diff_ts - diff_ts.shift(1)).dropna()\n",
    "        result = adfuller(diff_ts)\n",
    "    if result[0] < result[4]['1%'] :\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# ARIMA\n",
    "def ARIMA_fit(timeseries, s_id):\n",
    "    df_ts = np.log(timeseries+1)\n",
    "    df_ts = pd.Series([1 if i == 0 else i for i in df_ts ])\n",
    "    df_ts_mean = np.mean(df_ts)\n",
    "    df_ts_std = np.std(df_ts)\n",
    "    df_ts = (df_ts - df_ts_mean)/df_ts_std\n",
    "  # diff check\n",
    "    diff = -1\n",
    "    for i in range(0, 3):\n",
    "        if adfTest(df_ts, i):\n",
    "            diff = i\n",
    "\n",
    "    if diff == -1:\n",
    "        print(\"not stationary : \", s_id)\n",
    "        return -1\n",
    "\n",
    "    else:\n",
    "        p = q = range(3)\n",
    "        min_aic = 100000\n",
    "        d = range(diff+1)\n",
    "        min_param = []\n",
    "        pdq = list(itertools.product(p, d, q))\n",
    "    for param in pdq:\n",
    "        try:\n",
    "            mod = ARIMA(df_ts, order=(param[0], param[1], param[2]))\n",
    "            results = mod.fit()\n",
    "            if results.aic < min_aic:\n",
    "                min_aic = results.aic\n",
    "                min_param = [param[0], param[1], param[2]]\n",
    "                final_model = results\n",
    "        except:\n",
    "            continue\n",
    "    return sum(np.exp(final_model.forecast(steps=3)[0] * df_ts_std + df_ts_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "540ad7ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T08:05:31.471984Z",
     "start_time": "2021-12-28T07:23:49.779884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "not stationary :  2\n",
      "not stationary :  10\n",
      "not stationary :  13\n",
      "not stationary :  16\n",
      "not stationary :  19\n",
      "not stationary :  22\n",
      "not stationary :  40\n",
      "not stationary :  61\n",
      "not stationary :  83\n",
      "100\n",
      "not stationary :  102\n",
      "not stationary :  103\n",
      "not stationary :  104\n",
      "not stationary :  126\n",
      "not stationary :  130\n",
      "not stationary :  153\n",
      "not stationary :  159\n",
      "not stationary :  166\n",
      "not stationary :  170\n",
      "not stationary :  188\n",
      "200\n",
      "not stationary :  211\n",
      "not stationary :  229\n",
      "not stationary :  269\n",
      "300\n",
      "not stationary :  317\n",
      "not stationary :  325\n",
      "not stationary :  331\n",
      "not stationary :  335\n",
      "not stationary :  338\n",
      "not stationary :  339\n",
      "not stationary :  352\n",
      "not stationary :  365\n",
      "not stationary :  389\n",
      "not stationary :  392\n",
      "not stationary :  394\n",
      "400\n",
      "not stationary :  406\n",
      "not stationary :  407\n",
      "not stationary :  425\n",
      "not stationary :  440\n",
      "not stationary :  456\n",
      "not stationary :  459\n",
      "not stationary :  462\n",
      "not stationary :  466\n",
      "not stationary :  486\n",
      "not stationary :  487\n",
      "not stationary :  495\n",
      "not stationary :  498\n",
      "500\n",
      "not stationary :  500\n",
      "not stationary :  507\n",
      "not stationary :  529\n",
      "not stationary :  547\n",
      "not stationary :  554\n",
      "not stationary :  560\n",
      "not stationary :  583\n",
      "600\n",
      "not stationary :  601\n",
      "not stationary :  608\n",
      "not stationary :  613\n",
      "not stationary :  625\n",
      "not stationary :  674\n",
      "not stationary :  682\n",
      "not stationary :  694\n",
      "not stationary :  695\n",
      "700\n",
      "not stationary :  720\n",
      "not stationary :  731\n",
      "not stationary :  738\n",
      "not stationary :  739\n",
      "not stationary :  745\n",
      "not stationary :  750\n",
      "not stationary :  751\n",
      "not stationary :  755\n",
      "not stationary :  756\n",
      "not stationary :  759\n",
      "not stationary :  773\n",
      "not stationary :  778\n",
      "800\n",
      "not stationary :  808\n",
      "not stationary :  827\n",
      "not stationary :  831\n",
      "not stationary :  847\n",
      "not stationary :  852\n",
      "not stationary :  856\n",
      "not stationary :  861\n",
      "not stationary :  877\n",
      "not stationary :  885\n",
      "not stationary :  896\n",
      "900\n",
      "not stationary :  913\n",
      "not stationary :  925\n",
      "not stationary :  927\n",
      "not stationary :  933\n",
      "not stationary :  936\n",
      "not stationary :  940\n",
      "not stationary :  949\n",
      "not stationary :  958\n",
      "not stationary :  962\n",
      "not stationary :  965\n",
      "not stationary :  967\n",
      "not stationary :  969\n",
      "not stationary :  980\n",
      "not stationary :  982\n",
      "not stationary :  985\n",
      "not stationary :  988\n",
      "1000\n",
      "not stationary :  1012\n",
      "not stationary :  1021\n",
      "not stationary :  1025\n",
      "not stationary :  1027\n",
      "not stationary :  1028\n",
      "not stationary :  1029\n",
      "not stationary :  1038\n",
      "not stationary :  1046\n",
      "not stationary :  1058\n",
      "not stationary :  1072\n",
      "not stationary :  1073\n",
      "not stationary :  1074\n",
      "not stationary :  1087\n",
      "1100\n",
      "not stationary :  1106\n",
      "not stationary :  1109\n",
      "not stationary :  1113\n",
      "not stationary :  1148\n",
      "not stationary :  1150\n",
      "not stationary :  1158\n",
      "not stationary :  1173\n",
      "not stationary :  1182\n",
      "not stationary :  1189\n",
      "not stationary :  1199\n",
      "not stationary :  1213\n",
      "not stationary :  1220\n",
      "not stationary :  1235\n",
      "not stationary :  1242\n",
      "not stationary :  1244\n",
      "not stationary :  1251\n",
      "not stationary :  1254\n",
      "not stationary :  1255\n",
      "not stationary :  1263\n",
      "not stationary :  1274\n",
      "not stationary :  1283\n",
      "not stationary :  1294\n",
      "1300\n",
      "not stationary :  1337\n",
      "not stationary :  1356\n",
      "not stationary :  1374\n",
      "not stationary :  1384\n",
      "1400\n",
      "not stationary :  1423\n",
      "not stationary :  1432\n",
      "not stationary :  1456\n",
      "not stationary :  1466\n",
      "not stationary :  1477\n",
      "not stationary :  1487\n",
      "not stationary :  1489\n",
      "not stationary :  1497\n",
      "1500\n",
      "not stationary :  1502\n",
      "not stationary :  1508\n",
      "not stationary :  1516\n",
      "not stationary :  1517\n",
      "not stationary :  1521\n",
      "not stationary :  1548\n",
      "not stationary :  1552\n",
      "not stationary :  1553\n",
      "not stationary :  1557\n",
      "not stationary :  1580\n",
      "not stationary :  1583\n",
      "not stationary :  1592\n",
      "1600\n",
      "not stationary :  1611\n",
      "not stationary :  1619\n",
      "not stationary :  1694\n",
      "1700\n",
      "not stationary :  1705\n",
      "not stationary :  1720\n",
      "not stationary :  1722\n",
      "not stationary :  1727\n",
      "not stationary :  1730\n",
      "not stationary :  1739\n",
      "not stationary :  1754\n",
      "not stationary :  1755\n",
      "not stationary :  1773\n",
      "not stationary :  1779\n",
      "1800\n",
      "not stationary :  1813\n",
      "not stationary :  1829\n",
      "not stationary :  1834\n",
      "not stationary :  1835\n",
      "not stationary :  1837\n",
      "not stationary :  1864\n",
      "not stationary :  1869\n",
      "not stationary :  1877\n",
      "not stationary :  1878\n",
      "not stationary :  1880\n",
      "not stationary :  1888\n",
      "not stationary :  1894\n",
      "not stationary :  1897\n",
      "1900\n",
      "not stationary :  1906\n",
      "not stationary :  1937\n",
      "not stationary :  1943\n",
      "not stationary :  1949\n",
      "not stationary :  1953\n",
      "not stationary :  1957\n",
      "not stationary :  1963\n",
      "not stationary :  1965\n",
      "not stationary :  1978\n",
      "not stationary :  1979\n",
      "not stationary :  1982\n",
      "not stationary :  1994\n",
      "2000\n",
      "not stationary :  2001\n",
      "not stationary :  2019\n",
      "not stationary :  2025\n",
      "not stationary :  2029\n",
      "not stationary :  2032\n",
      "not stationary :  2036\n",
      "not stationary :  2039\n",
      "not stationary :  2043\n",
      "not stationary :  2045\n",
      "not stationary :  2050\n",
      "not stationary :  2057\n",
      "not stationary :  2067\n",
      "not stationary :  2068\n",
      "not stationary :  2092\n",
      "2100\n",
      "not stationary :  2103\n",
      "not stationary :  2106\n",
      "not stationary :  2109\n",
      "Wall time: 41min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "unique_store_id = df_prep['store_id'].unique()\n",
    "unique_store_id = [i for i in unique_store_id if i not in no_data_store_id]\n",
    "not_stationary_lst = []\n",
    "random_state = 100\n",
    "ts_predict = {}\n",
    "for one_store_id in unique_store_id:\n",
    "    if one_store_id % 100 == 0:\n",
    "        print(one_store_id)\n",
    "    df_month_sampling_amount = df_prep[df_prep['store_id'] == one_store_id]['amount'].resample('M').sum()\n",
    "    arima_predict_ = ARIMA_fit(df_month_sampling_amount, one_store_id)\n",
    "    if arima_predict_ == -1:\n",
    "        not_stationary_lst.append(one_store_id)\n",
    "    else:\n",
    "        ts_predict[one_store_id] = arima_predict_\n",
    "    \n",
    "len(not_stationary_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4359e7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T08:23:46.142490Z",
     "start_time": "2021-12-28T08:23:46.116886Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_score = {}\n",
    "def rf_prediction(df_, forward_step, random_state):\n",
    "  # 예측 값을 shift함.\n",
    "    df_['predict_val'] = df_['amount'].shift(-forward_step)\n",
    "\n",
    "    df_train = df_.iloc[:df_.shape[0]-1, :]\n",
    "    df_train.dropna(inplace=True)\n",
    "  # 마지막 value -> final predict\n",
    "    final_predict_value = df_.iloc[df_.shape[0]-1,  df_.columns != 'predict_val' ]\n",
    "    X = df_train.loc[:, df_.columns != 'predict_val']\n",
    "    Y = df_train['predict_val']\n",
    "  #x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)\n",
    "  \n",
    "    param_grid = {\n",
    "        'bootstrap': [True],\n",
    "        'max_depth': [2, 3, 4],\n",
    "        'max_features': ['auto', 'sqrt', 4],\n",
    "        'min_samples_leaf': [3, 4],\n",
    "        'min_samples_split': [2, 4],\n",
    "        'n_estimators': [3, 5, 7]\n",
    "    }\n",
    "\n",
    "    rf_model = RandomForestRegressor()\n",
    "    grid_search = GridSearchCV(estimator = rf_model, param_grid = param_grid, scoring='neg_mean_absolute_error',\n",
    "                          cv = 3, n_jobs = -1)\n",
    "  \n",
    "    grid_search.fit(X.values, Y.values)\n",
    "    best_grid = grid_search.best_estimator_\n",
    "    rf_score[s_id] = grid_search.best_score_\n",
    "    return best_grid.predict([final_predict_value.values])\n",
    "\n",
    "\n",
    "def df_replace_outlier(df_):\n",
    "    cols = list(df_.columns)\n",
    "    for col in cols:\n",
    "        df_col_series = df_[col]\n",
    "        qtile = df_col_series.quantile(0.2)\n",
    "        for idx, val in df_col_series.items():\n",
    "            if val <= qtile:\n",
    "                df_.loc[idx][col] = qtile\n",
    "    return df_\n",
    "\n",
    "\n",
    "def preprocessed_for_rf(df_ts, feature_lags):\n",
    "    month_sample_idx = df_ts.resample('M').sum().index\n",
    "  \n",
    "    df_result = pd.DataFrame(index=month_sample_idx)\n",
    "  # 한달 결제 횟수\n",
    "    df_result['pay_count'] = (df_ts['store_id'].resample('M').count()).fillna(0)\n",
    "\n",
    "  # 월별 해당 지역에 대한 전체 결제 금액\n",
    "    month_sampling_region = df_prep[df_prep['region'] == df_ts['region'][0]].resample('M')\n",
    "    df_result['region_total_amount'] = month_sampling_region['amount'].sum()\n",
    "\n",
    "  # 월별 해당 지역에서 결제한 가게의 수\n",
    "    df_result['region_store_count'] = 1\n",
    "    for idx in month_sample_idx:\n",
    "        df_result.loc[idx, 'region_store_count'] = len(month_sampling_region.store_id.unique().loc[idx])\n",
    "  \n",
    "  # 월별 해당 지역에 대한 평균 매출 금액\n",
    "    df_result['region_mean_amount'] = (df_result['region_total_amount'] / df_result['region_store_count']).fillna(0)\n",
    "\n",
    "  # 월별 업종에 대한 전체 결제 금액\n",
    "    month_sampling_business = df_prep[df_prep['type_of_business'] == df_ts['type_of_business'][0]].resample('M')\n",
    "    df_result['business_total_amount'] = month_sampling_business['amount'].sum()\n",
    "\n",
    "    df_result['business_store_count'] = 1\n",
    "    for idx in month_sample_idx:\n",
    "        df_result.loc[idx, 'business_store_count'] = len(month_sampling_business.store_id.unique().loc[idx])\n",
    "  \n",
    "    df_result['business_mean_amount'] = (df_result['business_total_amount'] / df_result['business_store_count']).fillna(0)\n",
    "  \n",
    "    del df_result['region_total_amount']\n",
    "    del df_result['region_store_count']\n",
    "    del df_result['business_total_amount']\n",
    "    del df_result['business_store_count']\n",
    "\n",
    "    df_result['amount'] = df_ts.resample('M')['amount'].sum()\n",
    "  #print(df_result.columns)\n",
    "    df_result = df_replace_outlier(df_result)\n",
    "  \n",
    "    cols = df_result.columns\n",
    "  # lag변수 생성\n",
    "    for col in cols:\n",
    "        for lag in range(1, feature_lags + 1):\n",
    "            df_result[col + \"_lag_\" + str(lag)] = df_result[col].shift(lag)\n",
    "  #display(df_result)\n",
    "    df_result.dropna(inplace=True)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8e19c44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T08:49:17.118012Z",
     "start_time": "2021-12-28T08:23:56.280772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n",
      "50 560\n",
      "100 1025\n",
      "150 1548\n",
      "200 2036\n",
      "Wall time: 25min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "random_state = 100\n",
    "not_stationary_prediction = {}\n",
    "not_stationary_store_id = not_stationary_lst\n",
    "\n",
    "df_not_stationary = df_prep[df_prep['store_id'].isin(not_stationary_store_id)]\n",
    "\n",
    "lag_num = 3\n",
    "for idx, s_id in enumerate(not_stationary_store_id):\n",
    "    if idx % 50 == 0:\n",
    "        print(idx, s_id)\n",
    "    df_tmp = df_not_stationary[df_not_stationary['store_id'] == s_id]\n",
    "    df_train = preprocessed_for_rf(df_tmp, feature_lags = lag_num)\n",
    "    predict_val = []\n",
    "  # 3달 예측\n",
    "    for d in range(1, 4):\n",
    "        predict_val.append(rf_prediction(df_train, d, random_state))\n",
    "    not_stationary_prediction[s_id] = sum(predict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de4f2de8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:34:51.440778Z",
     "start_time": "2021-12-28T08:53:29.598072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n",
      "50 560\n",
      "100 1025\n",
      "150 1548\n",
      "200 2036\n",
      "Wall time: 41min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "random_state = 100\n",
    "not_stationary_prediction = {}\n",
    "not_stationary_store_id = not_stationary_lst\n",
    "\n",
    "df_not_stationary = df_prep[df_prep['store_id'].isin(not_stationary_store_id)]\n",
    "\n",
    "lag_num = 3\n",
    "for idx, s_id in enumerate(not_stationary_store_id):\n",
    "    if idx % 50 == 0:\n",
    "        print(idx, s_id)\n",
    "    df_tmp = df_not_stationary[df_not_stationary['store_id'] == s_id]\n",
    "    df_train = preprocessed_for_rf(df_tmp, feature_lags = lag_num)\n",
    "    predict_val = []\n",
    "  # 3달 예측\n",
    "    for d in range(1, 4):\n",
    "        predict_val.append(rf_prediction(df_train, d, random_state))\n",
    "    not_stationary_prediction[s_id] = sum(predict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f58b165b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-28T09:36:16.383551Z",
     "start_time": "2021-12-28T09:36:15.702794Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sub_store_id_lst = df_sub['store_id'].unique()\n",
    "for s_id in df_sub_store_id_lst:\n",
    "    final_value = 0\n",
    "    if s_id in ts_predict.keys():\n",
    "        final_value = ts_predict[s_id]\n",
    "    elif s_id in no_data_store_id:\n",
    "        final_value = 0\n",
    "    elif s_id in not_stationary_lst:\n",
    "        final_value = not_stationary_prediction[s_id]\n",
    "    else:\n",
    "        print(\"no store id : \", s_id)\n",
    "    df_sub.iloc[df_sub[df_sub['store_id'] == s_id].index[0], 1] = final_value\n",
    "df_sub.to_csv('funda_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28471a39",
   "metadata": {},
   "source": [
    "result?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
